{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from keras.datasets import mnist\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, AveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from keras import backend as K"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n\n"
        }
      ],
      "execution_count": 1,
      "metadata": {},
      "id": "365ea34c"
    },
    {
      "cell_type": "code",
      "source": [
        "img_rows, img_cols = 28, 28"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {},
      "id": "1a01a598"
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {},
      "id": "b2ef2624"
    },
    {
      "cell_type": "code",
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {},
      "id": "db195ab5"
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "x_train shape: (60000, 28, 28, 1)\n60000 train samples\n10000 test samples\n"
        }
      ],
      "execution_count": 5,
      "metadata": {},
      "id": "891e795b"
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "            samplewise_center=False,  # set each sample mean to 0\n",
        "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "            samplewise_std_normalization=False,  # divide each input by its std\n",
        "            zca_whitening=False,  # apply ZCA whitening\n",
        "            rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "            zoom_range = 0.1, # Randomly zoom image \n",
        "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "            horizontal_flip=False,  # randomly flip images\n",
        "            vertical_flip=False)  # randomly flip images\n"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {},
      "id": "8160f0b3"
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "print(y_train[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
        }
      ],
      "execution_count": 7,
      "metadata": {},
      "id": "53a1f4c0"
    },
    {
      "cell_type": "code",
      "source": [
        "#defining these prior to model to increase readability and debugging\n",
        "batch_size = 128\n",
        "epochs = 5"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {},
      "id": "23f706d4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1)"
      ],
      "metadata": {},
      "id": "b988c159"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model-1"
      ],
      "metadata": {},
      "id": "2de0c77c"
    },
    {
      "cell_type": "code",
      "source": [
        "def Model1():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=2, data_format='channels_last',\n",
        "                     input_shape=(28, 28, 1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
        "    model.add(Conv2D(filters=16, kernel_size=(4, 4), activation='relu', strides=2, data_format='channels_last'))\n",
        "    model.add(MaxPooling2D(pool_size=(4, 4), strides=2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(8, activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.\n",
        "                  optimizers.Adam(learning_rate=0.01),metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train, batch_size=128,epochs=5,verbose=1,validation_data=(x_test, y_test))\n",
        "    score=model.evaluate(x_test, y_test, verbose=0)\n",
        "    \n",
        "    return score[1]"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {},
      "id": "4508d9f1"
    },
    {
      "cell_type": "code",
      "source": [
        "res = np.zeros(3)\n",
        "for i in range(3):\n",
        "    res[i] = Model1()\n",
        "np.mean(res)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nWARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n\nEpoch 1/5\nWARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n\nWARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n\n469/469 [==============================] - 5s 8ms/step - loss: 0.7121 - accuracy: 0.7564 - val_loss: 0.3214 - val_accuracy: 0.8972\nEpoch 2/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.3124 - accuracy: 0.9026 - val_loss: 0.2365 - val_accuracy: 0.9245\nEpoch 3/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.2485 - accuracy: 0.9222 - val_loss: 0.2328 - val_accuracy: 0.9267\nEpoch 4/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.2164 - accuracy: 0.9331 - val_loss: 0.2067 - val_accuracy: 0.9352\nEpoch 5/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.2054 - accuracy: 0.9370 - val_loss: 0.1619 - val_accuracy: 0.9491\nEpoch 1/5\n469/469 [==============================] - 4s 7ms/step - loss: 0.8609 - accuracy: 0.7111 - val_loss: 0.4418 - val_accuracy: 0.8630\nEpoch 2/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.4380 - accuracy: 0.8623 - val_loss: 0.3613 - val_accuracy: 0.8871\nEpoch 3/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8816 - val_loss: 0.3886 - val_accuracy: 0.8745\nEpoch 4/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.3548 - accuracy: 0.8890 - val_loss: 0.3182 - val_accuracy: 0.9011\nEpoch 5/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.3307 - accuracy: 0.8976 - val_loss: 0.3033 - val_accuracy: 0.9048\nEpoch 1/5\n469/469 [==============================] - 4s 7ms/step - loss: 0.6626 - accuracy: 0.7786 - val_loss: 0.3603 - val_accuracy: 0.8836\nEpoch 2/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.2940 - accuracy: 0.9073 - val_loss: 0.2429 - val_accuracy: 0.9231\nEpoch 3/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.2374 - accuracy: 0.9262 - val_loss: 0.2258 - val_accuracy: 0.9299\nEpoch 4/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.2044 - accuracy: 0.9361 - val_loss: 0.2131 - val_accuracy: 0.9348\nEpoch 5/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.1887 - accuracy: 0.9415 - val_loss: 0.1626 - val_accuracy: 0.9514\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "0.9350999991099039"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {},
      "id": "96f8435b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model-2"
      ],
      "metadata": {},
      "id": "05204f94"
    },
    {
      "cell_type": "code",
      "source": [
        "def Model2():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=2, data_format='channels_last',\n",
        "                     input_shape=(28, 28, 1)))\n",
        "    model.add(AveragePooling2D(pool_size=(2, 2), strides=1))\n",
        "    model.add(Conv2D(filters=16, kernel_size=(4, 4), activation='relu', strides=2, data_format='channels_last'))\n",
        "    model.add(AveragePooling2D(pool_size=(4, 4), strides=2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(8, activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.\n",
        "                  optimizers.Adam(learning_rate=0.01),metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train, batch_size=128,epochs=5,verbose=1,validation_data=(x_test, y_test))\n",
        "    score=model.evaluate(x_test, y_test, verbose=0)\n",
        "    \n",
        "    return score[1]"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {},
      "id": "56d46c8e"
    },
    {
      "cell_type": "code",
      "source": [
        "res = np.zeros(3)\n",
        "for i in range(3):\n",
        "    res[i] = Model2()\n",
        "np.mean(res)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/5\n469/469 [==============================] - 4s 7ms/step - loss: 1.0137 - accuracy: 0.6529 - val_loss: 0.5549 - val_accuracy: 0.8291\nEpoch 2/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.4834 - accuracy: 0.8479 - val_loss: 0.3873 - val_accuracy: 0.8781\nEpoch 3/5\n469/469 [==============================] - 3s 6ms/step - loss: 0.3708 - accuracy: 0.8855 - val_loss: 0.2933 - val_accuracy: 0.9100\nEpoch 4/5\n469/469 [==============================] - 3s 6ms/step - loss: 0.3190 - accuracy: 0.9041 - val_loss: 0.2664 - val_accuracy: 0.9153\nEpoch 5/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.2875 - accuracy: 0.9118 - val_loss: 0.2439 - val_accuracy: 0.9264\nEpoch 1/5\n469/469 [==============================] - 4s 7ms/step - loss: 0.8710 - accuracy: 0.7049 - val_loss: 0.4061 - val_accuracy: 0.8710\nEpoch 2/5\n469/469 [==============================] - 3s 6ms/step - loss: 0.3653 - accuracy: 0.8871 - val_loss: 0.2660 - val_accuracy: 0.9217\nEpoch 3/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.2907 - accuracy: 0.9106 - val_loss: 0.2522 - val_accuracy: 0.9222\nEpoch 4/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.2476 - accuracy: 0.9237 - val_loss: 0.2452 - val_accuracy: 0.9272\nEpoch 5/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.2291 - accuracy: 0.9295 - val_loss: 0.2207 - val_accuracy: 0.9295\nEpoch 1/5\n469/469 [==============================] - 4s 7ms/step - loss: 1.3791 - accuracy: 0.4921 - val_loss: 0.8494 - val_accuracy: 0.6911\nEpoch 2/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.7551 - accuracy: 0.7413 - val_loss: 0.5989 - val_accuracy: 0.8059\nEpoch 3/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.6035 - accuracy: 0.8059 - val_loss: 0.5459 - val_accuracy: 0.8215\nEpoch 4/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.5259 - accuracy: 0.8334 - val_loss: 0.5042 - val_accuracy: 0.8370\nEpoch 5/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.4685 - accuracy: 0.8523 - val_loss: 0.4209 - val_accuracy: 0.8680\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "0.9079666535059611"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {},
      "id": "297d0076"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model-3"
      ],
      "metadata": {},
      "id": "d9924db5"
    },
    {
      "cell_type": "code",
      "source": [
        "def Model3():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=2, padding='same', data_format='channels_last',\n",
        "                     input_shape=(28, 28, 1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
        "    model.add(Conv2D(filters=16, kernel_size=(4, 4), activation='relu', strides=2, data_format='channels_last'))\n",
        "    model.add(MaxPooling2D(pool_size=(4, 4), strides=2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(8, activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.\n",
        "                  optimizers.Adam(learning_rate=0.01),metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train, batch_size=128,epochs=5,verbose=1,validation_data=(x_test, y_test))\n",
        "    score=model.evaluate(x_test, y_test, verbose=0)\n",
        "    \n",
        "    return score[1]"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {},
      "id": "789770ef"
    },
    {
      "cell_type": "code",
      "source": [
        "res = np.zeros(3)\n",
        "for i in range(3):\n",
        "    res[i] = Model3()\n",
        "np.mean(res)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/5\n469/469 [==============================] - 4s 7ms/step - loss: 0.7510 - accuracy: 0.7373 - val_loss: 0.4198 - val_accuracy: 0.8636\nEpoch 2/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.3688 - accuracy: 0.8822 - val_loss: 0.2949 - val_accuracy: 0.9081\nEpoch 3/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.2957 - accuracy: 0.9079 - val_loss: 0.2328 - val_accuracy: 0.9265\nEpoch 4/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.2406 - accuracy: 0.9253 - val_loss: 0.2511 - val_accuracy: 0.9200\nEpoch 5/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.2188 - accuracy: 0.9323 - val_loss: 0.1710 - val_accuracy: 0.9461\nEpoch 1/5\n469/469 [==============================] - 4s 7ms/step - loss: 0.8211 - accuracy: 0.7115 - val_loss: 0.5123 - val_accuracy: 0.8320\nEpoch 2/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.4603 - accuracy: 0.8530 - val_loss: 0.4044 - val_accuracy: 0.8740\nEpoch 3/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8797 - val_loss: 0.3494 - val_accuracy: 0.8908\nEpoch 4/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.3278 - accuracy: 0.8980 - val_loss: 0.3023 - val_accuracy: 0.9083\nEpoch 5/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.3085 - accuracy: 0.9050 - val_loss: 0.3100 - val_accuracy: 0.9034\nEpoch 1/5\n469/469 [==============================] - 4s 7ms/step - loss: 1.0748 - accuracy: 0.6147 - val_loss: 0.7366 - val_accuracy: 0.7459\nEpoch 2/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.7062 - accuracy: 0.7649 - val_loss: 0.6907 - val_accuracy: 0.7686\nEpoch 3/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.6002 - accuracy: 0.8066 - val_loss: 0.5617 - val_accuracy: 0.8245\nEpoch 4/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.5157 - accuracy: 0.8362 - val_loss: 0.4720 - val_accuracy: 0.8539\nEpoch 5/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.4695 - accuracy: 0.8539 - val_loss: 0.4287 - val_accuracy: 0.8680\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "0.9058333237965902"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {},
      "id": "ee32ef89"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model-4"
      ],
      "metadata": {},
      "id": "f0227ffc"
    },
    {
      "cell_type": "code",
      "source": [
        "def Model4():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=2, padding='valid', data_format='channels_last',\n",
        "                     input_shape=(28, 28, 1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
        "    model.add(Conv2D(filters=16, kernel_size=(4, 4), activation='relu', strides=2, data_format='channels_last'))\n",
        "    model.add(MaxPooling2D(pool_size=(4, 4), strides=2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(8, activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.\n",
        "                  optimizers.Adam(learning_rate=0.01),metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train, batch_size=128,epochs=5,verbose=1,validation_data=(x_test, y_test))\n",
        "    score=model.evaluate(x_test, y_test, verbose=0)\n",
        "    \n",
        "    return score[1]"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {},
      "id": "642cabe3"
    },
    {
      "cell_type": "code",
      "source": [
        "res = np.zeros(3)\n",
        "for i in range(3):\n",
        "    res[i] = Model4()\n",
        "np.mean(res)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/5\n469/469 [==============================] - 4s 8ms/step - loss: 0.9516 - accuracy: 0.6625 - val_loss: 0.5174 - val_accuracy: 0.8239\nEpoch 2/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.4756 - accuracy: 0.8453 - val_loss: 0.3668 - val_accuracy: 0.8836\nEpoch 3/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.3788 - accuracy: 0.8798 - val_loss: 0.3167 - val_accuracy: 0.8994\nEpoch 4/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.3373 - accuracy: 0.8939 - val_loss: 0.3467 - val_accuracy: 0.8920\nEpoch 5/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.3086 - accuracy: 0.9026 - val_loss: 0.2984 - val_accuracy: 0.9062\nEpoch 1/5\n469/469 [==============================] - 4s 8ms/step - loss: 1.0527 - accuracy: 0.6385 - val_loss: 0.6967 - val_accuracy: 0.7770\nEpoch 2/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.5923 - accuracy: 0.8129 - val_loss: 0.5534 - val_accuracy: 0.8187\nEpoch 3/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.4911 - accuracy: 0.8460 - val_loss: 0.4221 - val_accuracy: 0.8693\nEpoch 4/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.4379 - accuracy: 0.8625 - val_loss: 0.4000 - val_accuracy: 0.8720\nEpoch 5/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.4017 - accuracy: 0.8746 - val_loss: 0.3530 - val_accuracy: 0.8927\nEpoch 1/5\n469/469 [==============================] - 4s 7ms/step - loss: 0.6509 - accuracy: 0.7800 - val_loss: 0.2857 - val_accuracy: 0.9147\nEpoch 2/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.2713 - accuracy: 0.9150 - val_loss: 0.2378 - val_accuracy: 0.9239\nEpoch 3/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.2202 - accuracy: 0.9303 - val_loss: 0.2106 - val_accuracy: 0.9354\nEpoch 4/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.1976 - accuracy: 0.9388 - val_loss: 0.1744 - val_accuracy: 0.9474\nEpoch 5/5\n469/469 [==============================] - 3s 7ms/step - loss: 0.1820 - accuracy: 0.9430 - val_loss: 0.1649 - val_accuracy: 0.9495\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "0.9161333441734314"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {},
      "id": "14f83c8c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2)"
      ],
      "metadata": {},
      "id": "0a1ff261"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner --upgrade"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: keras-tuner in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.6)\nRequirement already satisfied: kt-legacy in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-tuner) (1.0.5)\nRequirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-tuner) (21.3)\nRequirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-tuner) (2.28.1)\nRequirement already satisfied: keras in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-tuner) (2.15.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->keras-tuner) (3.0.9)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (1.26.11)\nRequirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2022.9.14)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 17,
      "metadata": {},
      "id": "b58c2ca9"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras_tuner as kt"
      ],
      "outputs": [],
      "execution_count": 47,
      "metadata": {},
      "id": "25c8ec7f"
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "outputs": [],
      "execution_count": 48,
      "metadata": {},
      "id": "5ff370b7"
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Convolutional layer with hyperparameter search for filters, kernel size, and padding\n",
        "    model.add(Conv2D(filters=hp.Int('conv1_filters', min_value=16, max_value=64, step=8),\n",
        "                     kernel_size=hp.Int('conv1_kernel', min_value=3, max_value=4, step=1),  # Separate Int hyperparameters for width and height\n",
        "                     activation='relu',\n",
        "                     strides=2,\n",
        "                     padding=hp.Choice('conv1_padding', values=['valid', 'same']),\n",
        "                     input_shape=(28, 28, 1)))\n",
        "\n",
        "    # Pooling layer with hyperparameter search for kernel size and stride\n",
        "    model.add(MaxPooling2D(pool_size=hp.Int('pool1_size', min_value=2, max_value=4, step=1),  # Separate Int hyperparameters for width and height\n",
        "                           strides=hp.Choice('pool1_stride', values=[1, 2])))\n",
        "\n",
        "    # Similar hyperparameter search for the second convolutional and pooling layers\n",
        "    model.add(Conv2D(filters=hp.Int('conv2_filters', min_value=16, max_value=64, step=8),\n",
        "                     kernel_size=hp.Int('conv2_kernel', min_value=3, max_value=4, step=1),  # Separate Int hyperparameters for width and height\n",
        "                     activation='relu',\n",
        "                     strides=2,\n",
        "                     padding=hp.Choice('conv2_padding', values=['valid', 'same'])))\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=hp.Int('pool2_size', min_value=2, max_value=4, step=1),  # Separate Int hyperparameters for width and height\n",
        "                           strides=hp.Choice('pool2_stride', values=[1, 2])))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Fully connected layers with hyperparameter search for neurons and activation function\n",
        "    model.add(Dense(units=hp.Int('dense1_units', min_value=4, max_value=32, step=4),\n",
        "                    activation=hp.Choice('dense1_activation', values=['relu', 'tanh', 'sigmoid'])))\n",
        "\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    # Adam optimizer with hyperparameter search for learning rate\n",
        "    optimizer = Adam(learning_rate=hp.Float('learning_rate', min_value=0.0001, max_value=0.1, sampling='log'))\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "outputs": [],
      "execution_count": 50,
      "metadata": {},
      "id": "e13bea7a"
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_tuner import RandomSearch\n",
        "from keras_tuner.engine.hyperparameters import HyperParameters"
      ],
      "outputs": [],
      "execution_count": 51,
      "metadata": {},
      "id": "8aa677b3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the RandomSearch tuner\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='accuracy',\n",
        "    max_trials=5,\n",
        "    directory='hyperparameter_tuning',\n",
        "    project_name='my_hyperparameter_search')\n",
        "\n",
        "\n",
        "# Run the hyperparameter search for 3 times\n",
        "for i in range(3):\n",
        "    print(f\"Running search iteration {i + 1}\")\n",
        "    \n",
        "    tuner.search(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=5,\n",
        "    validation_data=(x_test, y_test),\n",
        "    batch_size=128,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)],\n",
        "    verbose=1)\n",
        "\n",
        " \n",
        "    \n",
        "    # Get the best hyperparameters and build the final model\n",
        "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "    model = tuner.hypermodel.build(best_hps)\n",
        "    \n",
        "    # Train the model with the best hyperparameters for 5 epochs\n",
        "    history = model.fit(x_train, y_train, batch_size=128, epochs=5, verbose=1, validation_data=(x_test, y_test))\n",
        "    \n",
        "    # Print out the best hyperparameters\n",
        "    print(f\"Best Hyperparameters - Trial {i + 1}:\")\n",
        "    print(f\"Filters in Convolutional Layer 1: {best_hps.get('conv1_filters')}\")\n",
        "    print(f\"Kernel Size in Convolutional Layer 1: {best_hps.get('conv1_kernel')}\")\n",
        "    print(f\"Padding in Convolutional Layer 1: {best_hps.get('conv1_padding')}\")\n",
        "    # Add similar print statements for other hyperparameters\n",
        "    \n",
        "    # Print the best validation accuracy achieved\n",
        "    best_val_accuracy = max(history.history['val_accuracy'])\n",
        "    print(f\"Best Validation Accuracy: {best_val_accuracy}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Reloading Tuner from hyperparameter_tuning\\my_hyperparameter_search\\tuner0.json\nRunning search iteration 1\nEpoch 1/5\n469/469 [==============================] - 4s 6ms/step - loss: 1.3217 - accuracy: 0.6084 - val_loss: 0.7369 - val_accuracy: 0.7776\nEpoch 2/5\n469/469 [==============================] - 3s 6ms/step - loss: 0.5455 - accuracy: 0.8475 - val_loss: 0.4032 - val_accuracy: 0.8863\nEpoch 3/5\n469/469 [==============================] - 3s 6ms/step - loss: 0.4130 - accuracy: 0.8818 - val_loss: 0.3647 - val_accuracy: 0.8936\nEpoch 4/5\n469/469 [==============================] - 3s 6ms/step - loss: 0.3676 - accuracy: 0.8918 - val_loss: 0.3773 - val_accuracy: 0.8901\nEpoch 5/5\n469/469 [==============================] - 3s 6ms/step - loss: 0.3271 - accuracy: 0.9037 - val_loss: 0.2824 - val_accuracy: 0.9179\nBest Hyperparameters - Trial 1:\nFilters in Convolutional Layer 1: 32\nKernel Size in Convolutional Layer 1: 4\nPadding in Convolutional Layer 1: same\nBest Validation Accuracy: 0.917900025844574\nRunning search iteration 2\nEpoch 1/5\n469/469 [==============================] - 4s 6ms/step - loss: 1.0340 - accuracy: 0.6953 - val_loss: 0.4494 - val_accuracy: 0.8851\nEpoch 2/5\n469/469 [==============================] - 3s 6ms/step - loss: 0.3774 - accuracy: 0.8938 - val_loss: 0.3113 - val_accuracy: 0.9104\nEpoch 3/5\n469/469 [==============================] - 3s 6ms/step - loss: 0.3046 - accuracy: 0.9126 - val_loss: 0.2709 - val_accuracy: 0.9251\nEpoch 4/5\n469/469 [==============================] - 3s 6ms/step - loss: 0.2790 - accuracy: 0.9177 - val_loss: 0.2396 - val_accuracy: 0.9339\nEpoch 5/5\n469/469 [==============================] - 3s 6ms/step - loss: 0.2611 - accuracy: 0.9253 - val_loss: 0.2520 - val_accuracy: 0.9281\nBest Hyperparameters - Trial 2:\nFilters in Convolutional Layer 1: 32\nKernel Size in Convolutional Layer 1: 4\nPadding in Convolutional Layer 1: same\nBest Validation Accuracy: 0.933899998664856\nRunning search iteration 3\nEpoch 1/5\n469/469 [==============================] - 4s 6ms/step - loss: 1.0731 - accuracy: 0.6875 - val_loss: 0.5100 - val_accuracy: 0.8673\nEpoch 2/5\n469/469 [==============================] - 3s 6ms/step - loss: 0.4260 - accuracy: 0.8813 - val_loss: 0.3606 - val_accuracy: 0.8896\nEpoch 3/5\n469/469 [==============================] - 3s 6ms/step - loss: 0.3221 - accuracy: 0.9089 - val_loss: 0.3147 - val_accuracy: 0.9166\nEpoch 4/5\n469/469 [==============================] - 3s 6ms/step - loss: 0.3068 - accuracy: 0.9108 - val_loss: 0.2219 - val_accuracy: 0.9371\nEpoch 5/5\n469/469 [==============================] - 3s 6ms/step - loss: 0.2745 - accuracy: 0.9227 - val_loss: 0.2881 - val_accuracy: 0.9170\nBest Hyperparameters - Trial 3:\nFilters in Convolutional Layer 1: 32\nKernel Size in Convolutional Layer 1: 4\nPadding in Convolutional Layer 1: same\nBest Validation Accuracy: 0.9370999932289124\n"
        }
      ],
      "execution_count": 54,
      "metadata": {},
      "id": "813ce374"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "b434e216"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}